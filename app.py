"""
Sistema Integrado de Confian√ßa para Detec√ß√£o de IA
Implementa√ß√£o Completa das Melhorias de Confian√ßa
"""

import numpy as np
import re
import time
from collections import Counter, defaultdict
from typing import Dict, List, Tuple, Optional
import hashlib
import json
from datetime import datetime, timedelta
import logging

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultiDetectorEnsemble:
    """Sistema de m√∫ltiplos detectores para aumentar confian√ßa"""
    
    def __init__(self):
        self.detectors = {
            'statistical': StatisticalDetector(),
            'pattern': PatternDetector(),
            'syntactic': SyntacticDetector(),
            'semantic': SemanticDetector(),
            'perplexity': PerplexityDetector()
        }
        self.min_detectors = 3
    
    def calculate_ensemble_confidence(self, text: str) -> Dict:
        """Calcula confian√ßa baseada na concord√¢ncia entre detectores"""
        results = {}
        predictions = []
        
        for name, detector in self.detectors.items():
            try:
                result = detector.analyze(text)
                results[name] = result
                predictions.append(result['ai_probability'])
                logger.info(f"Detector {name}: {result['ai_probability']:.1f}%")
            except Exception as e:
                logger.warning(f"Detector {name} falhou: {e}")
                continue
        
        if len(predictions) < self.min_detectors:
            return {
                'confidence': 25.0,
                'reason': f'Apenas {len(predictions)} detectores dispon√≠veis (m√≠nimo: {self.min_detectors})',
                'detector_count': len(predictions),
                'agreement_score': 0.0
            }
        
        # Calcula m√©tricas de concord√¢ncia
        mean_pred = np.mean(predictions)
        std_pred = np.std(predictions)
        
        # Agreement score baseado no desvio padr√£o
        # Quanto menor o desvio, maior a concord√¢ncia
        max_std = 50.0  # M√°ximo desvio esperado
        agreement_score = max(0, 1 - (std_pred / max_std))
        
        # Confian√ßa baseada na concord√¢ncia
        base_confidence = agreement_score * 100
        
        # B√¥nus por ter mais detectores
        detector_bonus = min((len(predictions) - self.min_detectors) * 5, 15)
        
        # B√¥nus por consenso forte (todos na mesma dire√ß√£o)
        consensus_bonus = 0
        if all(p > 60 for p in predictions) or all(p < 40 for p in predictions):
            consensus_bonus = 10
        
        final_confidence = min(base_confidence + detector_bonus + consensus_bonus, 100.0)
        
        return {
            'confidence': final_confidence,
            'agreement_score': agreement_score,
            'detector_count': len(predictions),
            'mean_prediction': mean_pred,
            'std_prediction': std_pred,
            'individual_results': results,
            'consensus_bonus': consensus_bonus
        }

class TextQualityAnalyzer:
    """Analisador de qualidade do texto para ajustar confian√ßa"""
    
    def assess_text_quality(self, text: str) -> Dict:
        """Avalia qualidade do texto em m√∫ltiplas dimens√µes"""
        
        quality_factors = {
            'length_adequacy': self._assess_length(text),
            'structure_clarity': self._assess_structure(text),
            'language_consistency': self._assess_language(text),
            'content_coherence': self._assess_coherence(text),
            'domain_specificity': self._assess_domain(text)
        }
        
        # Score de qualidade geral (m√©dia ponderada)
        weights = {
            'length_adequacy': 0.25,
            'structure_clarity': 0.25,
            'language_consistency': 0.20,
            'content_coherence': 0.20,
            'domain_specificity': 0.10
        }
        
        overall_quality = sum(
            quality_factors[factor] * weights[factor]
            for factor in quality_factors
        )
        
        # Converte qualidade em confian√ßa
        quality_confidence = self._quality_to_confidence(overall_quality)
        
        return {
            'quality_score': overall_quality,
            'quality_confidence': quality_confidence,
            'quality_factors': quality_factors,
            'recommendations': self._generate_quality_recommendations(quality_factors)
        }
    
    def _assess_length(self, text: str) -> float:
        """Avalia adequa√ß√£o do comprimento do texto"""
        word_count = len(text.split())
        
        # Curva de adequa√ß√£o baseada no comprimento
        if word_count < 30:
            return 0.1  # Muito curto para an√°lise confi√°vel
        elif word_count < 50:
            return 0.3  # Curto, mas analis√°vel
        elif word_count < 100:
            return 0.6  # Adequado para an√°lise b√°sica
        elif word_count < 300:
            return 0.9  # Bom para an√°lise
        elif word_count < 1000:
            return 1.0  # Ideal para an√°lise
        elif word_count < 3000:
            return 0.9  # Muito longo, mas ainda bom
        else:
            return 0.7  # Muito longo, pode ter ru√≠do
    
    def _assess_structure(self, text: str) -> float:
        """Avalia clareza da estrutura do texto"""
        sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        
        if not sentences:
            return 0.0
        
        # M√©tricas de estrutura
        sentence_lengths = [len(s.split()) for s in sentences]
        avg_sentence_length = np.mean(sentence_lengths)
        sentence_variety = np.std(sentence_lengths) if len(sentence_lengths) > 1 else 0
        
        structure_score = 0.0
        
        # Comprimento de frase adequado (8-30 palavras)
        if 8 <= avg_sentence_length <= 30:
            structure_score += 0.4
        elif 5 <= avg_sentence_length <= 40:
            structure_score += 0.2
        
        # Variedade nas frases (indica estrutura natural)
        if sentence_variety > 2:
            structure_score += 0.3
        elif sentence_variety > 1:
            structure_score += 0.1
        
        # Organiza√ß√£o em par√°grafos
        if len(paragraphs) > 1:
            structure_score += 0.3
        elif len(paragraphs) == 1 and len(sentences) > 3:
            structure_score += 0.1
        
        return min(structure_score, 1.0)
    
    def _assess_language(self, text: str) -> float:
        """Avalia consist√™ncia da linguagem"""
        # Detecta mistura de idiomas ou inconsist√™ncias
        words = re.findall(r'\b\w+\b', text.lower())
        
        if not words:
            return 0.0
        
        # M√©tricas de consist√™ncia
        word_freq = Counter(words)
        
        # Verifica repeti√ß√£o excessiva (sinal de baixa qualidade)
        most_common_freq = word_freq.most_common(1)[0][1] if word_freq else 0
        repetition_ratio = most_common_freq / len(words)
        
        # Verifica diversidade vocabular
        unique_ratio = len(set(words)) / len(words)
        
        language_score = 0.0
        
        # Penaliza repeti√ß√£o excessiva
        if repetition_ratio < 0.1:  # Menos de 10% de repeti√ß√£o da palavra mais comum
            language_score += 0.5
        elif repetition_ratio < 0.2:
            language_score += 0.3
        
        # Premia diversidade vocabular
        if unique_ratio > 0.6:
            language_score += 0.5
        elif unique_ratio > 0.4:
            language_score += 0.3
        
        return min(language_score, 1.0)
    
    def _assess_coherence(self, text: str) -> float:
        """Avalia coer√™ncia do conte√∫do"""
        sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]
        
        if len(sentences) < 2:
            return 0.5  # N√£o h√° como avaliar coer√™ncia
        
        # An√°lise de conectivos e transi√ß√µes
        connectives = [
            r'\b(al√©m disso|portanto|consequentemente|dessa forma|por outro lado)\b',
            r'\b(entretanto|contudo|todavia|no entanto)\b',
            r'\b(primeiramente|em seguida|finalmente|por fim)\b',
            r'\b(por exemplo|ou seja|isto √©|em outras palavras)\b'
        ]
        
        connective_count = 0
        for pattern in connectives:
            connective_count += len(re.findall(pattern, text.lower()))
        
        # Normaliza pela quantidade de frases
        connective_density = connective_count / len(sentences)
        
        coherence_score = 0.0
        
        # Densidade adequada de conectivos (indica estrutura l√≥gica)
        if 0.1 <= connective_density <= 0.3:
            coherence_score += 0.6
        elif 0.05 <= connective_density <= 0.5:
            coherence_score += 0.4
        
        # Verifica repeti√ß√£o de estruturas (pode indicar IA)
        sentence_starts = [s.split()[0].lower() if s.split() else '' for s in sentences]
        start_variety = len(set(sentence_starts)) / len(sentence_starts) if sentence_starts else 0
        
        if start_variety > 0.7:
            coherence_score += 0.4
        elif start_variety > 0.5:
            coherence_score += 0.2
        
        return min(coherence_score, 1.0)
    
    def _assess_domain(self, text: str) -> float:
        """Avalia especificidade do dom√≠nio"""
        # Detecta se o texto √© de um dom√≠nio espec√≠fico
        # Textos especializados tendem a ser mais confi√°veis para an√°lise
        
        technical_indicators = [
            r'\b\d+%\b',  # Percentuais
            r'\b\d{4}\b',  # Anos
            r'\b[A-Z]{2,}\b',  # Siglas
            r'\b(pesquisa|estudo|an√°lise|dados|resultados)\b',  # Termos t√©cnicos
            r'\b(segundo|conforme|de acordo com)\b'  # Cita√ß√µes
        ]
        
        indicator_count = 0
        for pattern in technical_indicators:
            indicator_count += len(re.findall(pattern, text))
        
        words = len(text.split())
        if words == 0:
            return 0.0
        
        # Densidade de indicadores t√©cnicos
        technical_density = indicator_count / words
        
        # Score baseado na densidade
        if technical_density > 0.05:
            return 1.0  # Texto t√©cnico/especializado
        elif technical_density > 0.02:
            return 0.8  # Alguma especificidade
        elif technical_density > 0.01:
            return 0.6  # Pouca especificidade
        else:
            return 0.4  # Texto gen√©rico
    
    def _quality_to_confidence(self, quality_score: float) -> float:
        """Converte score de qualidade em n√≠vel de confian√ßa"""
        # Fun√ß√£o n√£o-linear para converter qualidade em confian√ßa
        if quality_score >= 0.8:
            return 90.0 + (quality_score - 0.8) * 50  # 90-100%
        elif quality_score >= 0.6:
            return 70.0 + (quality_score - 0.6) * 100  # 70-90%
        elif quality_score >= 0.4:
            return 50.0 + (quality_score - 0.4) * 100  # 50-70%
        elif quality_score >= 0.2:
            return 30.0 + (quality_score - 0.2) * 100  # 30-50%
        else:
            return quality_score * 150  # 0-30%
    
    def _generate_quality_recommendations(self, quality_factors: Dict) -> List[str]:
        """Gera recomenda√ß√µes baseadas na qualidade"""
        recommendations = []
        
        if quality_factors['length_adequacy'] < 0.5:
            recommendations.append("üìè Texto muito curto - considere an√°lise de texto mais longo")
        
        if quality_factors['structure_clarity'] < 0.5:
            recommendations.append("üìù Estrutura pouco clara - pode afetar precis√£o da an√°lise")
        
        if quality_factors['language_consistency'] < 0.5:
            recommendations.append("üî§ Inconsist√™ncias lingu√≠sticas detectadas")
        
        if quality_factors['content_coherence'] < 0.5:
            recommendations.append("üîó Baixa coer√™ncia textual - resultado pode ser menos confi√°vel")
        
        if all(score > 0.7 for score in quality_factors.values()):
            recommendations.append("‚úÖ Texto de alta qualidade - an√°lise muito confi√°vel")
        
        return recommendations

class ConfidenceCalibrator:
    """Sistema de calibra√ß√£o baseado em dados hist√≥ricos"""
    
    def __init__(self, data_file: str = "historical_data.json"):
        self.data_file = data_file
        self.historical_data = self._load_historical_data()
        self.min_samples = 50
    
    def _load_historical_data(self) -> List[Dict]:
        """Carrega dados hist√≥ricos do arquivo"""
        try:
            with open(self.data_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.info("Arquivo de dados hist√≥ricos n√£o encontrado. Criando novo.")
            return []
        except Exception as e:
            logger.error(f"Erro ao carregar dados hist√≥ricos: {e}")
            return []
    
    def _save_historical_data(self):
        """Salva dados hist√≥ricos no arquivo"""
        try:
            with open(self.data_file, 'w') as f:
                json.dump(self.historical_data, f, indent=2)
        except Exception as e:
            logger.error(f"Erro ao salvar dados hist√≥ricos: {e}")
    
    def add_historical_result(self, prediction: float, actual_label: int,
                            text_features: Dict, confidence: float = None):
        """Adiciona resultado hist√≥rico para calibra√ß√£o futura"""
        entry = {
            'prediction': prediction,
            'actual': actual_label,
            'features': text_features,
            'confidence': confidence,
            'timestamp': datetime.now().isoformat(),
            'correct': self._is_prediction_correct(prediction, actual_label)
        }
        
        self.historical_data.append(entry)
        
        # Limita tamanho dos dados hist√≥ricos
        if len(self.historical_data) > 10000:
            # Remove entradas mais antigas
            self.historical_data = self.historical_data[-8000:]
        
        self._save_historical_data()
        logger.info(f"Adicionado resultado hist√≥rico: pred={prediction:.1f}%, actual={actual_label}")
    
    def calibrate_confidence(self, raw_prediction: float, text_features: Dict) -> Dict:
        """Calibra confian√ßa baseada em dados hist√≥ricos"""
        
        if len(self.historical_data) < self.min_samples:
            return {
                'calibrated_confidence': self._conservative_confidence(raw_prediction),
                'reason': f'Dados insuficientes ({len(self.historical_data)}/{self.min_samples})',
                'historical_accuracy': None,
                'similar_cases': 0
            }
        
        # Encontra casos similares
        similar_cases = self._find_similar_cases(text_features)
        
        if len(similar_cases) < 10:
            return {
                'calibrated_confidence': self._conservative_confidence(raw_prediction),
                'reason': f'Poucos casos similares ({len(similar_cases)})',
                'historical_accuracy': None,
                'similar_cases': len(similar_cases)
            }
        
        # Calcula precis√£o em casos similares
        bin_accuracy = self._calculate_bin_accuracy(raw_prediction, similar_cases)
        
        # Calibra confian√ßa baseada na precis√£o hist√≥rica
        calibrated_confidence = bin_accuracy * 100
        
        # Ajusta baseado na quantidade de casos similares
        sample_adjustment = min(len(similar_cases) / 50, 1.0)  # M√°ximo em 50 casos
        calibrated_confidence *= (0.7 + 0.3 * sample_adjustment)
        
        return {
            'calibrated_confidence': min(calibrated_confidence, 95.0),
            'historical_accuracy': bin_accuracy,
            'similar_cases': len(similar_cases),
            'reason': 'Calibrado com dados hist√≥ricos'
        }
    
    def _find_similar_cases(self, target_features: Dict) -> List[Dict]:
        """Encontra casos hist√≥ricos similares"""
        similar_cases = []
        
        for case in self.historical_data:
            similarity = self._calculate_feature_similarity(
                target_features, case['features']
            )
            
            if similarity >= 0.7:  # Threshold de similaridade
                case['similarity'] = similarity
                similar_cases.append(case)
        
        # Ordena por similaridade
        similar_cases.sort(key=lambda x: x['similarity'], reverse=True)
        
        return similar_cases[:100]  # M√°ximo 100 casos mais similares
    
    def _calculate_feature_similarity(self, features1: Dict, features2: Dict) -> float:
        """Calcula similaridade entre features de dois textos"""
        
        # Features num√©ricas para compara√ß√£o
        numeric_features = ['word_count', 'sentence_count', 'avg_word_length', 'unique_words']
        
        similarities = []
        
        for feature in numeric_features:
            if feature in features1 and feature in features2:
                val1, val2 = features1[feature], features2[feature]
                if val1 == 0 and val2 == 0:
                    similarities.append(1.0)
                elif val1 == 0 or val2 == 0:
                    similarities.append(0.0)
                else:
                    # Similaridade baseada na diferen√ßa relativa
                    diff = abs(val1 - val2) / max(val1, val2)
                    similarity = max(0, 1 - diff)
                    similarities.append(similarity)
        
        return np.mean(similarities) if similarities else 0.0
    
    def _calculate_bin_accuracy(self, prediction: float, similar_cases: List[Dict]) -> float:
        """Calcula precis√£o em bin de predi√ß√£o similar"""
        
        # Define bin baseado na predi√ß√£o
        bin_size = 20  # Bins de 20%
        bin_start = (prediction // bin_size) * bin_size
        bin_end = bin_start + bin_size
        
        # Filtra casos no mesmo bin
        bin_cases = [
            case for case in similar_cases
            if bin_start <= case['prediction'] < bin_end
        ]
        
        if len(bin_cases) < 5:
            # Se poucos casos no bin, usa bin mais amplo
            bin_size = 40
            bin_start = (prediction // bin_size) * bin_size
            bin_end = bin_start + bin_size
            
            bin_cases = [
                case for case in similar_cases
                if bin_start <= case['prediction'] < bin_end
            ]
        
        if len(bin_cases) < 3:
            # Se ainda poucos casos, usa todos os casos similares
            bin_cases = similar_cases
        
        # Calcula precis√£o
        correct_predictions = sum(1 for case in bin_cases if case['correct'])
        accuracy = correct_predictions / len(bin_cases) if bin_cases else 0.5
        
        return accuracy
    
    def _is_prediction_correct(self, prediction: float, actual_label: int) -> bool:
        """Verifica se predi√ß√£o estava correta"""
        predicted_label = 1 if prediction > 50 else 0
        return predicted_label == actual_label
    
    def _conservative_confidence(self, prediction: float) -> float:
        """Retorna confian√ßa conservadora quando n√£o h√° dados suficientes"""
        # Confian√ßa baseada na dist√¢ncia de 50% (zona de incerteza)
        distance_from_center = abs(prediction - 50)
        conservative_confidence = 30 + (distance_from_center / 50) * 40  # 30-70%
        return min(conservative_confidence, 70.0)

class SeparationMarginAnalyzer:
    """Analisador de margem de separa√ß√£o para confian√ßa"""
    
    def __init__(self):
        self.uncertainty_zone = (40, 60)  # Zona de maior incerteza
        self.high_confidence_zones = [(0, 25), (75, 100)]  # Zonas de alta confian√ßa
    
    def calculate_margin_confidence(self, prediction: float) -> Dict:
        """Calcula confian√ßa baseada na margem de separa√ß√£o"""
        
        # Identifica zona atual
        current_zone = self._identify_zone(prediction)
        
        # Calcula dist√¢ncia da zona de incerteza
        uncertainty_distance = self._calculate_uncertainty_distance(prediction)
        
        # Calcula confian√ßa baseada na margem
        margin_confidence = self._distance_to_confidence(uncertainty_distance)
        
        # Aplica multiplicadores baseados na zona
        zone_multiplier = self._get_zone_multiplier(current_zone)
        adjusted_confidence = margin_confidence * zone_multiplier
        
        # B√¥nus para predi√ß√µes muito extremas
        extreme_bonus = self._calculate_extreme_bonus(prediction)
        final_confidence = min(adjusted_confidence + extreme_bonus, 100.0)
        
        return {
            'margin_confidence': final_confidence,
            'current_zone': current_zone,
            'uncertainty_distance': uncertainty_distance,
            'zone_multiplier': zone_multiplier,
            'extreme_bonus': extreme_bonus,
            'recommendation': self._generate_margin_recommendation(current_zone, final_confidence)
        }
    
    def _identify_zone(self, prediction: float) -> str:
        """Identifica zona de predi√ß√£o"""
        if prediction <= 25:
            return 'very_high_human'
        elif prediction <= 40:
            return 'high_human'
        elif prediction <= 60:
            return 'uncertainty'
        elif prediction <= 75:
            return 'high_ai'
        else:
            return 'very_high_ai'
    
    def _calculate_uncertainty_distance(self, prediction: float) -> float:
        """Calcula dist√¢ncia da zona de incerteza"""
        uncertainty_center = 50
        uncertainty_radius = 10  # Zona de ¬±10% ao redor de 50%
        
        if self.uncertainty_zone[0] <= prediction <= self.uncertainty_zone[1]:
            # Dentro da zona de incerteza
            return 0.0
        elif prediction < self.uncertainty_zone[0]:
            # Abaixo da zona de incerteza
            return self.uncertainty_zone[0] - prediction
        else:
            # Acima da zona de incerteza
            return prediction - self.uncertainty_zone[1]
    
    def _distance_to_confidence(self, distance: float) -> float:
        """Converte dist√¢ncia em confian√ßa"""
        # Fun√ß√£o n√£o-linear: confian√ßa cresce rapidamente com a dist√¢ncia
        max_distance = 40  # Dist√¢ncia m√°xima considerada
        normalized_distance = min(distance / max_distance, 1.0)
        
        # Fun√ß√£o exponencial para crescimento r√°pido
        confidence = 40 + (60 * (normalized_distance ** 0.7))
        return confidence
    
    def _get_zone_multiplier(self, zone: str) -> float:
        """Retorna multiplicador baseado na zona"""
        multipliers = {
            'very_high_human': 1.0,
            'high_human': 0.9,
            'uncertainty': 0.4,
            'high_ai': 0.9,
            'very_high_ai': 1.0
        }
        return multipliers.get(zone, 0.5)
    
    def _calculate_extreme_bonus(self, prediction: float) -> float:
        """Calcula b√¥nus para predi√ß√µes extremas"""
        if prediction <= 15 or prediction >= 85:
            return 10.0  # B√¥nus alto para predi√ß√µes muito extremas
        elif prediction <= 25 or prediction >= 75:
            return 5.0   # B√¥nus m√©dio para predi√ß√µes extremas
        else:
            return 0.0   # Sem b√¥nus
    
    def _generate_margin_recommendation(self, zone: str, confidence: float) -> str:
        """Gera recomenda√ß√£o baseada na zona e confian√ßa"""
        recommendations = {
            'very_high_human': f'Resultado muito confi√°vel ({confidence:.0f}%) - muito provavelmente texto humano',
            'high_human': f'Resultado confi√°vel ({confidence:.0f}%) - provavelmente texto humano',
            'uncertainty': f'Resultado incerto ({confidence:.0f}%) - zona de ambiguidade, considere an√°lise adicional',
            'high_ai': f'Resultado confi√°vel ({confidence:.0f}%) - provavelmente texto de IA',
            'very_high_ai': f'Resultado muito confi√°vel ({confidence:.0f}%) - muito provavelmente texto de IA'
        }
        return recommendations.get(zone, f'Resultado com {confidence:.0f}% de confian√ßa')

# Classes de detectores individuais (implementa√ß√µes simplificadas)
class StatisticalDetector:
    def analyze(self, text: str) -> Dict:
        words = text.split()
        if not words:
            return {'ai_probability': 50.0}
        
        # An√°lise estat√≠stica simples
        avg_word_length = np.mean([len(word) for word in words])
        unique_ratio = len(set(words)) / len(words)
        
        # IA tende a ter palavras mais longas e menos diversidade
        ai_score = (avg_word_length / 10) * 50 + (1 - unique_ratio) * 50
        return {'ai_probability': min(ai_score, 100.0)}

class PatternDetector:
    def analyze(self, text: str) -> Dict:
        ai_patterns = [
            r'\b(al√©m disso|portanto|consequentemente)\b',
            r'\b(√© importante notar|vale ressaltar)\b',
            r'\b(em resumo|em conclus√£o)\b'
        ]
        
        pattern_count = 0
        for pattern in ai_patterns:
            pattern_count += len(re.findall(pattern, text.lower()))
        
        words = len(text.split())
        if words == 0:
            return {'ai_probability': 50.0}
        
        pattern_density = (pattern_count / words) * 1000
        ai_score = min(pattern_density * 20, 100.0)
        
        return {'ai_probability': ai_score}

class SyntacticDetector:
    def analyze(self, text: str) -> Dict:
        sentences = re.split(r'[.!?]+', text)
        if not sentences:
            return {'ai_probability': 50.0}
        
        sentence_lengths = [len(s.split()) for s in sentences if s.strip()]
        if not sentence_lengths:
            return {'ai_probability': 50.0}
        
        # IA tende a ter frases mais uniformes
        avg_length = np.mean(sentence_lengths)
        std_length = np.std(sentence_lengths)
        
        # Baixa varia√ß√£o = mais prov√°vel IA
        if std_length == 0:
            uniformity = 1.0
        else:
            uniformity = 1 / (1 + std_length / avg_length)
        
        ai_score = uniformity * 100
        return {'ai_probability': ai_score}

class SemanticDetector:
    def analyze(self, text: str) -> Dict:
        # An√°lise sem√¢ntica simplificada
        formal_words = ['entretanto', 'todavia', 'outrossim', 'destarte', 'ademais']
        formal_count = sum(text.lower().count(word) for word in formal_words)
        
        words = len(text.split())
        if words == 0:
            return {'ai_probability': 50.0}
        
        formality_ratio = formal_count / words
        ai_score = min(formality_ratio * 500, 100.0)
        
        return {'ai_probability': ai_score}

class PerplexityDetector:
    def analyze(self, text: str) -> Dict:
        words = text.lower().split()
        if len(words) < 4:
            return {'ai_probability': 50.0}
        
        # Aproxima√ß√£o simples de perplexidade
        bigrams = [(words[i], words[i+1]) for i in range(len(words)-1)]
        bigram_counts = Counter(bigrams)
        word_counts = Counter(words)
        
        log_prob_sum = 0
        for bigram in bigrams:
            prob = bigram_counts[bigram] / word_counts[bigram[0]]
            if prob > 0:
                log_prob_sum += np.log2(prob)
        
        avg_log_prob = log_prob_sum / len(bigrams)
        perplexity = 2 ** (-avg_log_prob)
        
        # Normaliza perplexidade para score de IA
        normalized_perplexity = min(perplexity / 100, 1.0)
        ai_score = normalized_perplexity * 100
        
        return {'ai_probability': ai_score}

# Exemplo de uso
def exemplo_sistema_confianca():
    """Exemplo de uso do sistema integrado de confian√ßa"""
    
    # Texto de exemplo
    texto = """
    A intelig√™ncia artificial representa uma das mais significativas inova√ß√µes tecnol√≥gicas 
    da era moderna. Al√©m disso, √© importante notar que seus impactos se estendem por 
    diversos setores da sociedade. Consequentemente, devemos considerar tanto os benef√≠cios 
    quanto os desafios que essa tecnologia apresenta. Em conclus√£o, a IA continuar√° a 
    moldar nosso futuro de maneiras que ainda estamos come√ßando a compreender.
    """
    
    # Inicializa componentes
    ensemble = MultiDetectorEnsemble()
    quality_analyzer = TextQualityAnalyzer()
    calibrator = ConfidenceCalibrator()
    margin_analyzer = SeparationMarginAnalyzer()
    
    print("=== SISTEMA INTEGRADO DE CONFIAN√áA ===\n")
    
    # 1. An√°lise do ensemble
    print("1. An√°lise do Ensemble de Detectores:")
    ensemble_result = ensemble.calculate_ensemble_confidence(texto)
    print(f"   Confian√ßa do Ensemble: {ensemble_result['confidence']:.1f}%")
    print(f"   Detectores ativos: {ensemble_result['detector_count']}")
    print(f"   Score de concord√¢ncia: {ensemble_result['agreement_score']:.2f}")
    print()
    
    # 2. An√°lise de qualidade
    print("2. An√°lise de Qualidade do Texto:")
    quality_result = quality_analyzer.assess_text_quality(texto)
    print(f"   Confian√ßa da Qualidade: {quality_result['quality_confidence']:.1f}%")
    print(f"   Score de qualidade: {quality_result['quality_score']:.2f}")
    for factor, score in quality_result['quality_factors'].items():
        print(f"   - {factor}: {score:.2f}")
    print()
    
    # 3. An√°lise de margem
    prediction = ensemble_result['mean_prediction']
    print("3. An√°lise de Margem de Separa√ß√£o:")
    margin_result = margin_analyzer.calculate_margin_confidence(prediction)
    print(f"   Confian√ßa da Margem: {margin_result['margin_confidence']:.1f}%")
    print(f"   Zona atual: {margin_result['current_zone']}")
    print(f"   Dist√¢ncia da incerteza: {margin_result['uncertainty_distance']:.1f}")
    print()
    
    # 4. Calibra√ß√£o (exemplo sem dados hist√≥ricos)
    print("4. Calibra√ß√£o com Dados Hist√≥ricos:")
    text_features = {
        'word_count': len(texto.split()),
        'sentence_count': len(re.split(r'[.!?]+', texto)),
        'avg_word_length': np.mean([len(word) for word in texto.split()]),
        'unique_words': len(set(texto.split()))
    }
    
    calibration_result = calibrator.calibrate_confidence(prediction, text_features)
    print(f"   Confian√ßa Calibrada: {calibration_result['calibrated_confidence']:.1f}%")
    print(f"   Raz√£o: {calibration_result['reason']}")
    print()
    
    # 5. Confian√ßa final integrada
    print("5. Confian√ßa Final Integrada:")
    
    # Pesos para cada componente
    weights = {
        'ensemble': 0.30,
        'quality': 0.25,
        'margin': 0.25,
        'calibration': 0.20
    }
    
    # Calcula confian√ßa final
    final_confidence = (
        ensemble_result['confidence'] * weights['ensemble'] +
        quality_result['quality_confidence'] * weights['quality'] +
        margin_result['margin_confidence'] * weights['margin'] +
        calibration_result['calibrated_confidence'] * weights['calibration']
    )
    
    print(f"   CONFIAN√áA FINAL: {final_confidence:.1f}%")
    
    # Classifica√ß√£o da confian√ßa
    if final_confidence >= 85:
        nivel = "MUITO ALTA"
    elif final_confidence >= 70:
        nivel = "ALTA"
    elif final_confidence >= 55:
        nivel = "MODERADA"
    elif final_confidence >= 40:
        nivel = "BAIXA"
    else:
        nivel = "MUITO BAIXA"
    
    print(f"   N√≠vel de Confian√ßa: {nivel}")
    print(f"   Predi√ß√£o de IA: {prediction:.1f}%")

if __name__ == "__main__":
    exemplo_sistema_confianca()
